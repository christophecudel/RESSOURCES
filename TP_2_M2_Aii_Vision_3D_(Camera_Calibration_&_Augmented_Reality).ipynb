{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "740ee242",
      "metadata": {
        "id": "740ee242"
      },
      "source": [
        "# TP Vision Master - Calibration de caméras et incrustation (Partie 2)\n",
        "Ce notebook est une conversion du PDF contenant des exercices pour la calibration de caméras et l'incrustation d'images. Il inclut les codes et explications du TP.\n",
        "\n",
        "**Objectifs :**\n",
        "- Calibrer une caméra\n",
        "- Passer du repère monde au repère caméra et inversement\n",
        "- Proposer un scénario d'incrustration d'une image personnelle\n",
        "\n",
        "**Attention :** Interdiction d'utiliser la fonction utilisée dans la partie 1 :*cv2.projectPoints(My3Dpoints, rvecs[InxdexIm], tvecs[InxdexIm], mtx, dist)*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75056a93",
      "metadata": {
        "id": "75056a93"
      },
      "source": [
        "## Étape 1: Importation des bibliothèques nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bb9fb32",
      "metadata": {
        "id": "8bb9fb32"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import cv2\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fb0b2c7",
      "metadata": {
        "id": "0fb0b2c7"
      },
      "source": [
        "## Étape 2: Chargement des images et test de détection des coins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7828ad2c",
      "metadata": {
        "id": "7828ad2c"
      },
      "outputs": [],
      "source": [
        "FigSize = (10, 10)  # Permet d'ajuster la taille des images affichées\n",
        "\n",
        "# On extrait un tableau avec l'ensemble des fichiers images d'un dossier\n",
        "# images = ... (reprendre la méthode du TP1 avec le fichier MireRobot.zip\n",
        "\n",
        "\n",
        "# Test : lire l'image n°2 de cette séquence\n",
        "img = cv2.imread(images[1])\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Détection de coins sur image N&B\n",
        "\n",
        "# Test si coins bien détectés\n",
        "ret, corners = cv2.findChessboardCorners(gray, (10, 10), None)\n",
        "if ret:\n",
        "    cv2.drawChessboardCorners(img, (10, 10), corners, ret)\n",
        "    fig, ax = plt.subplots(figsize=FigSize)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Image originale et coins')\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Impossible de détecter les coins de l'image\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67111171",
      "metadata": {
        "id": "67111171"
      },
      "source": [
        "## Étape 3: Préparation des points objet et image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a7f3ae",
      "metadata": {
        "id": "70a7f3ae"
      },
      "outputs": [],
      "source": [
        "# Préparer les points objet (ici en cm)\n",
        "objp = np.zeros((10 * 10, 3), np.float32)\n",
        "objp[:, :2] = 15 * np.mgrid[0:10, 0:10].T.reshape(-1, 2)  # Dimensions des carreaux : 15x15 mm\n",
        "\n",
        "# Arrays pour stocker les points objet et image\n",
        "objpoints = []  # Points 3D dans l'espace réel\n",
        "imgpoints = []  # Points 2D dans le plan image\n",
        "\n",
        "# Critère pour optimisation dans les détections de coins\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25e7532d",
      "metadata": {
        "id": "25e7532d"
      },
      "source": [
        "## Étape 4: Calibration de la caméra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f6494c1",
      "metadata": {
        "id": "4f6494c1"
      },
      "outputs": [],
      "source": [
        "FigSize = (10, 10)  # Taille des images affichées\n",
        "cpt = 0\n",
        "\n",
        "for fname in images:\n",
        "    img = cv2.imread(fname)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Détection des coins\n",
        "    ret, corners = cv2.findChessboardCorners(gray, (10, 10), None)\n",
        "\n",
        "    # Si coins trouvés, affiner la détection\n",
        "    if ret:\n",
        "        cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
        "        objpoints.append(objp)\n",
        "        imgpoints.append(corners)\n",
        "        cv2.drawChessboardCorners(img, (10, 10), corners, ret)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f'Frame {cpt}')\n",
        "        plt.show()\n",
        "        clear_output(wait=True)\n",
        "    cpt += 1\n",
        "\n",
        "# Calcul de la matrice intrinsèque et des paramètres extrinsèques\n",
        "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
        "\n",
        "print('Matrice intrinsèque :')\n",
        "print(mtx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697d887b",
      "metadata": {
        "id": "697d887b"
      },
      "source": [
        "## Etape 1 : Construire la matrice de projection : Matrices mtx, R et T\n",
        "\n",
        "Après la calibration, nous obtenons les éléments suivants :\n",
        "\n",
        "- **mtx** : Matrice intrinsèque de la caméra (3x3), contenant des paramètres tels que la distance focale et le point principal.\n",
        "- **rvecs** et **tvecs** : Vecteurs rotation et translation associés à chaque image utilisée pour la calibration. Ces vecteurs définissent la relation entre le repère de la caméra et le repère du monde.\n",
        "- La matrice rotation (**R**) peut être obtenue à partir de `rvecs` avec :\n",
        "  ```python\n",
        "  R, _ = cv2.Rodrigues(rvecs[i])\n",
        "  ```\n",
        "\n",
        "Pour une image donnée, la transformation d’un point dans le repère monde vers le plan image est définie par :\n",
        "\n",
        "$$ s.p = \\text{mtx} \\cdot \\left( R | T \\right) \\cdot P  $$\n",
        "\n",
        "où :\n",
        "- $p$ est le point projeté dans le plan image\n",
        "- $s$ est un facteur d'échelle\n",
        "- $\\text{mtx}$ est la matrice intrinsèque (3x3),\n",
        "- $(R|T)$est une matrice (3x4) combinant rotation et translation,\n",
        "- $P$ est un point en coordonnées homogènes dans le repère monde."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bef994c",
      "metadata": {
        "id": "7bef994c"
      },
      "source": [
        "## Etape 2 : Projeter un point de la scène\n",
        "Pour réaliser cette tâche, vous devez utiliser les outils suivants :\n",
        "- Produit matriciel : `C = np.dot(A, B)`\n",
        "- Transposée d'une matrice : `A.T`\n",
        "- Construction d'une matrice (3x4) avec R et T :\n",
        "  ```python\n",
        "  Proj = np.zeros((3, 4))\n",
        "  Proj[0:3, 0:3] = R\n",
        "  Proj[:, 3] = T.T\n",
        "  ```\n",
        "- Pour afficher un point sur une image : `plt.plot(x, y, 'r+')`\n",
        "\n",
        "### Résumé :\n",
        "1. Extraire la rotation et translation de l'image courant  \n",
        "2. Construire la matrice projection \\( (R|T) \\).\n",
        "3. Multiplier cette matrice par les coordonnées homogènes \\( P \\) d’un point du repère monde.\n",
        "4. Projeter le résultat sur le plan image en divisant par \\( z \\) (homogénéisation des coordonnées).\n",
        "\n",
        "## Question 1 : projeter l'origine du repère"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9dffa45",
      "metadata": {
        "id": "e9dffa45"
      },
      "outputs": [],
      "source": [
        "# Compléter ce code pour afficher l'origine du repère de la mire sur l'image courante\n",
        "i = 0  # Index de l'image\n",
        "R, _ = cv2.Rodrigues(rvecs[i])\n",
        "T = tvecs[i]\n",
        "\n",
        "P = np.array([0, 0, 0, 1])  # Point d'origine dans le repère\n",
        "Proj = np.zeros((3, 4))\n",
        "Proj[0:3, 0:3] = ??\n",
        "Proj[:, 3] = ??\n",
        "\n",
        "p = np.dot(mtx, np.dot(??, ??))\n",
        "plt.plot(p[0]/p[2], p[1]/p[2], 'r+')  # Projection du point normalisé\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c99b466",
      "metadata": {
        "id": "3c99b466"
      },
      "source": [
        "## Question 2 : Incrustation d'une imagette sur le damier\n",
        "\n",
        "### Objectif\n",
        "Insérer une imagette de votre choix sur le damier détecté dans l'image.\n",
        "\n",
        "### Étapes à suivre\n",
        "1. Lire une imagette (exemple : une image de 100x100 pixels).\n",
        "2. Définir un tableau 2D \\( (2 \\times N) \\) contenant les coordonnées \\( (x, y) \\) de chaque pixel de l'imagette.\n",
        "3. Définir un tableau \\( (1 \\times N) \\) contenant les intensités de chaque pixel de l'imagette.\n",
        "4. Appliquer une transformation des coordonnées en pixels pour les adapter au repère monde (par exemple, avec un facteur de conversion basé sur la taille des carreaux).\n",
        "5. Créer un tableau \\( P \\) représentant les coordonnées \\( (X, Y, Z) \\) des pixels à incruster.\n",
        "6. Appliquer la transformation vue à la question précédente pour obtenir les coordonnées projetées.\n",
        "7. Modifier directement les pixels correspondants dans l'image de la scène, en utilisant les coordonnées projetées (arrondies)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97ca9abd",
      "metadata": {
        "id": "97ca9abd"
      },
      "outputs": [],
      "source": [
        "# Étape 1 : Charger une imagette (par exemple 100x100 pixels)\n",
        "imagette = cv2.imread('path_to_imagette.png')\n",
        "if imagette is not None:\n",
        "    # Redimensionner si nécessaire\n",
        "    imagette = cv2.resize(imagette, (100, 100))\n",
        "\n",
        "    # Étape 2 : Générer les coordonnées des pixels de l'imagette\n",
        "    h, w, _ = imagette.shape\n",
        "    x, y = np.meshgrid(range(w), range(h))\n",
        "    pixel_coords = np.vstack((x.ravel(), y.ravel()))  # Tableau 2D (2xN)\n",
        "\n",
        "    # Étape 3 : Extraire les intensités des pixels\n",
        "    intensities = imagette.reshape(-1, 3)  # Intensités sous forme (N, 3)\n",
        "\n",
        "    # Étape 4 : Conversion des coordonnées pour le repère monde\n",
        "    f = 30 / 100  # Facteur de conversion pour adapter l'échelle (30x30 mm)\n",
        "    world_coords = np.vstack((f * x.ravel(), f * y.ravel(), np.zeros(w * h)))  # (3xN)\n",
        "\n",
        "    # Étape 5 : Transformation des points monde vers image\n",
        "    proj_coords = np.dot(mtx, np.dot(Proj, np.vstack((world_coords, np.ones(world_coords.shape[1])))))\n",
        "    proj_coords = proj_coords[:2] / proj_coords[2]  # Homogénéisation\n",
        "\n",
        "    # Étape 6 : Modifier l'image en incrustant les pixels de l'imagette\n",
        "    for u in range(proj_coords.shape[1]):\n",
        "        x_proj, y_proj = int(proj_coords[0, u]), int(proj_coords[1, u])\n",
        "        if 0 <= x_proj < img.shape[1] and 0 <= y_proj < img.shape[0]:\n",
        "            img[y_proj, x_proj, :] = intensities[u]\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Image avec imagette incrustée')\n",
        "    plt.show()\n",
        "else:\n",
        "    print('Imagette introuvable. Veuillez fournir un chemin valide.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3 :\n",
        "Sur une l'image de votre choix :\n",
        "\n",
        "\n",
        "*   Créer une séquence d'images, où l'imagette inscrustée se soulève de la mire au rythme de 5 mm par nouvelle image\n",
        "*   Modifier la séquence pour ajouter une rotation de 5° de l'imagette pour chaque nouvelle image\n",
        "\n"
      ],
      "metadata": {
        "id": "Q180tkG4AJeF"
      },
      "id": "Q180tkG4AJeF"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}